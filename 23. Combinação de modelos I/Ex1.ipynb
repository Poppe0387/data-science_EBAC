{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "032cfbea-86cd-4fb7-8d19-cb8497741942",
   "metadata": {},
   "source": [
    "# **Bagging**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40321fbc-be49-42e0-a98a-fab0dade1535",
   "metadata": {},
   "source": [
    "## 1. Monte um passo a passo para o Bagging\n",
    "\n",
    "Passo 1: ***Preparação dos Dados***\n",
    "\n",
    "*Coleta de Dados:* Reúna o conjunto de dados que você utilizará para treinar e testar o modelo.\n",
    "*Pré-processamento:* Limpe os dados, lide com valores ausentes e normalize/escale os atributos conforme necessário.\n",
    "*Divisão dos Dados:* Separe os dados em conjuntos de treinamento e teste para avaliar a performance do modelo.\n",
    "\n",
    "Passo 2: ***Criação das Amostras Bootstrap***\n",
    "\n",
    "*Geração de Amostras:* Crie várias amostras do conjunto de dados de treinamento usando a técnica de bootstrap, onde cada amostra é gerada selecionando dados aleatórios com reposição.\n",
    "*Número de Amostras:* Decida quantas amostras bootstrap serão criadas. Um número comum é entre 50 e 100 amostras.\n",
    "\n",
    "Passo 3: ***Treinamento dos Modelos***\n",
    "\n",
    "*Modelo Base:* Escolha o modelo base que será usado para treinamento em cada amostra (por exemplo, uma árvore de decisão, regressão linear, etc.).\n",
    "*Treinamento Individual:* Treine um modelo separado em cada amostra bootstrap. Cada modelo aprenderá diferentes aspectos dos dados devido às variações nas amostras.\n",
    "\n",
    "Passo 4: ***Agregação das Previsões***\n",
    "\n",
    "*Previsão dos Modelos:* Para um novo dado de entrada, obtenha a previsão de cada modelo treinado.\n",
    "*Combinação das Previsões:* Para problemas de classificação, combine as previsões através de votação majoritária (a classe mais votada entre os modelos é a escolhida); Para problemas de regressão, combine as previsões tirando a média das previsões dos modelos.\n",
    "\n",
    "Passo 5: ***Avaliação do Modelo***\n",
    "\n",
    "*Teste no Conjunto de Teste:* Use o conjunto de dados de teste para avaliar o desempenho do modelo de Bagging.\n",
    "*Métricas de Avaliação:* Calcule métricas de desempenho, como acurácia, precisão, recall, F1-score (para classificação) ou erro quadrático médio, erro absoluto médio (para regressão).\n",
    "\n",
    "Passo 6: ***Análise e Ajustes Finais***\n",
    "\n",
    "*Análise de Resultados:* Analise as métricas de desempenho para verificar se o modelo atende às expectativas.\n",
    "*Ajustes:* Se necessário, experimente diferentes modelos base, número de amostras bootstrap ou outras configurações para otimizar o desempenho.\n",
    "*Comparação:* Compare o desempenho do modelo de Bagging com outros modelos para garantir que ele esteja proporcionando uma melhoria significativa.\n",
    "\n",
    "***Vantagens e Considerações***\n",
    "\n",
    "Vantagens: O Bagging reduz a variância do modelo e ajuda a prevenir overfitting, resultando em previsões mais estáveis e precisas.\n",
    "Considerações: Embora o Bagging melhore a estabilidade, ele pode aumentar o custo computacional devido ao treinamento de múltiplos modelos. Além disso, a escolha do modelo base e o número de amostras bootstrap podem impactar significativamente o desempenho.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d784f4-1f71-4fb5-916a-76b73dba5e2d",
   "metadata": {},
   "source": [
    "## 2. Explique com suas palavras o Bagging\n",
    "\n",
    "O Bagging, ou Bootstrap Aggregating, é uma técnica de ensemble learning utilizada para melhorar a precisão e a estabilidade de modelos de machine learning. A ideia principal é combinar vários modelos fracos (ou seja, modelos que têm um desempenho um pouco melhor do que a adivinhação aleatória) para criar um modelo forte que seja mais robusto e confiável. \n",
    "De uma forma geral ele funciona com as seguintes etapas: amostragem Bootstrap; treinamento de modelos e agregação. E como vantagens pode-se destacar: a redução de variância, a prevenção de overfitting e melhoria de precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed512e15-488c-444f-bbc6-75e9d9efa10a",
   "metadata": {},
   "source": [
    "## 3. Implementar em python o código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e6f84f2-ae26-4611-ba0b-f03d439e127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milla\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\milla\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do Bagging: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Acurácia do Bagging com SVM: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.ensemble import BaggingClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.datasets import load_iris\r\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "# Carregar o conjunto de dados Iris\r\n",
    "iris = load_iris()\r\n",
    "X = iris.data\r\n",
    "y = iris.target\r\n",
    "\r\n",
    "# Dividir o conjunto de dados em treinamento e teste\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
    "\r\n",
    "# Escolher o modelo base (Árvore de Decisão)\r\n",
    "base_model = DecisionTreeClassifier()\r\n",
    "\r\n",
    "# Configurar o BaggingClassifier\r\n",
    "bagging_model = BaggingClassifier(base_estimator=base_model, n_estimators=100, random_state=42)\r\n",
    "\r\n",
    "# Treinar o modelo Bagging\r\n",
    "bagging_model.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Fazer previsões no conjunto de teste\r\n",
    "y_pred = bagging_model.predict(X_test)\r\n",
    "\r\n",
    "# Calcular a acurácia\r\n",
    "accuracy = accuracy_score(y_test, y_pred)\r\n",
    "print(f'Acurácia do Bagging: {accuracy * 100:.2f}%')\r\n",
    "\r\n",
    "# Avaliar outras métricas\r\n",
    "print(classification_report(y_test, y_pred))\r\n",
    "print(confusion_matrix(y_test, y_pred))\r\n",
    "\r\n",
    "# Experimente diferentes modelos base e parâmetros\r\n",
    "# Exemplo com SVM como modelo base\r\n",
    "base_model_svm = SVC()\r\n",
    "bagging_model_svm = BaggingClassifier(base_estimator=base_model_svm, n_estimators=50, random_state=42)\r\n",
    "\r\n",
    "bagging_model_svm.fit(X_train, y_train)\r\n",
    "y_pred_svm = bagging_model_svm.predict(X_test)\r\n",
    "\r\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\r\n",
    "print(f'Acurácia do Bagging com SVM: {accuracy_svm * 100:.2f}%')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fc955-7f7a-4a2e-9339-99271021ceda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
